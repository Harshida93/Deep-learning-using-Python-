{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb310245c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalising data for better accuracy\n",
    "X_train=keras.utils.normalize(X_train)\n",
    "X_test=keras.utils.normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00617053 0.03702317 0.03702317 0.03702317 0.25916217 0.2797306\n",
      "  0.35994746 0.05347791 0.34143588 0.52449487 0.50804013 0.26121901\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.03783863 0.04540636 0.11856105 0.19423832\n",
      "  0.21441893 0.31910581 0.31910581 0.31910581 0.31910581 0.31910581\n",
      "  0.28378975 0.2169415  0.31910581 0.30523165 0.24595112 0.08072242\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06027503 0.29276441 0.31121595 0.31121595 0.31121595\n",
      "  0.31121595 0.31121595 0.31121595 0.31121595 0.31121595 0.30875574\n",
      "  0.11439954 0.10086841 0.10086841 0.06888574 0.047974   0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02405893 0.29271693 0.33816157 0.33816157 0.33816157\n",
      "  0.33816157 0.33816157 0.26464818 0.24326247 0.33014192 0.32212228\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.16401365 0.31982661 0.21936825 0.51869316\n",
      "  0.51869316 0.42028497 0.02255188 0.         0.08815734 0.31572627\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.04517963 0.00322712 0.49697592\n",
      "  0.81646044 0.29044047 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.4022081\n",
      "  0.73207661 0.54978085 0.00578717 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.03392574\n",
      "  0.58599009 0.78029206 0.21589108 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0912263  0.62815821 0.58645476 0.41703449 0.28149828 0.00260647\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17804778 0.52754898 0.55612455 0.55612455 0.26157637\n",
      "  0.05495302 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10382122 0.42912769 0.58370594 0.58370594\n",
      "  0.34607072 0.06229273 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.03864836 0.22464358 0.60871163\n",
      "  0.61112716 0.45170268 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.56810388\n",
      "  0.57723004 0.56810388 0.14601867 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.0973284  0.27505852 0.38719776 0.53530619\n",
      "  0.53530619 0.43797779 0.00423167 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0646848  0.24547053 0.37981588 0.41962191 0.41962191 0.41962191\n",
      "  0.41464616 0.3018624  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.03972867 0.1887112\n",
      "  0.36583488 0.41880645 0.41880645 0.41880645 0.41880645 0.33272765\n",
      "  0.12911819 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.03876324 0.11123366 0.35898134 0.42639568\n",
      "  0.42639568 0.42639568 0.42639568 0.33370097 0.13651403 0.00337072\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.02927437 0.27810651 0.35617149 0.41146752 0.41146752 0.41146752\n",
      "  0.41146752 0.317139   0.13010831 0.01463718 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.08516473 0.26633334\n",
      "  0.34994962 0.39175776 0.39175776 0.39175776 0.39175776 0.37782171\n",
      "  0.2059438  0.01703295 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.25195037 0.46870179\n",
      "  0.46870179 0.46870179 0.39274617 0.25009779 0.24454007 0.02964122\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Dropout,Flatten,Activation\n",
    "from keras.layers import Convolution2D,MaxPooling2D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshap x_train and x_test for inputting to the convolution layer. The new dimention can be gray or RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(60000,28,28,1)\n",
    "X_test=X_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0705 16:03:22.692012 4588033472 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0705 16:03:22.720853 4588033472 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0705 16:03:22.725831 4588033472 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0705 16:03:22.763597 4588033472 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 53,002\n",
      "Trainable params: 53,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#building model\n",
    "model= Sequential()\n",
    "model.add(Convolution2D(32,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Convolution2D(64,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0705 16:03:22.868571 4588033472 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0705 16:03:22.903428 4588033472 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0705 16:03:23.004804 4588033472 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0705 16:03:23.058343 4588033472 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.2336 - acc: 0.9292\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 24s 395us/step - loss: 0.0775 - acc: 0.9750\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 24s 399us/step - loss: 0.0545 - acc: 0.9827\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 25s 411us/step - loss: 0.0433 - acc: 0.9865\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.0347 - acc: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb313df198>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 124us/step\n"
     ]
    }
   ],
   "source": [
    "val_loss,val_acc=model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03552783978948137"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9882"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(prediction[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb4face518>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
